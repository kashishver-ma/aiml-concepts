{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8e2fafcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['expense_id', 'amount', 'merchant', 'description', 'category'], dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##loading data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"personal_expense_classification.csv\")\n",
    "df.head()\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aa5f53b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['expense_id', 'amount', 'merchant'],axis=1,inplace=True)\n",
    "df.head()\n",
    "df.columns\n",
    "df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "db0df609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, 2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.shape\n",
    "\n",
    "df.isnull().sum()\n",
    "df.dropna(inplace=True)\n",
    "df.shape\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2e8a9643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['description', 'category'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['wireless headphones purchase', 'monthly streaming subscription',\n",
       "       'morning coffee and muffin', 'ride to downtown office',\n",
       "       'smartphone screen protector', 'lunch combo meal',\n",
       "       'daily bus pass', 'premium music subscription',\n",
       "       'household cleaning supplies', 'iPad protective case',\n",
       "       'dinner delivery order', 'gasoline fill up',\n",
       "       'monthly video subscription', 'weekly grocery shopping',\n",
       "       'office software license', 'coffee and donut',\n",
       "       'airport pickup ride', 'monthly membership fee',\n",
       "       'personal care products', 'wireless charging pad',\n",
       "       'burrito bowl lunch', 'car fuel purchase',\n",
       "       'streaming service subscription', 'bulk household items',\n",
       "       'laptop mouse and keyboard', 'sandwich and chips', 'taxi to hotel',\n",
       "       'premium streaming service', 'vitamins and supplements',\n",
       "       'wireless router upgrade', 'chicken bucket meal',\n",
       "       'gas station fill up', 'streaming subscription',\n",
       "       'garden tools purchase', 'app store credit purchase',\n",
       "       'late night snack order', 'weekly train pass',\n",
       "       'ad free subscription', 'clothing and accessories',\n",
       "       'printer ink cartridges', 'breakfast sandwich meal',\n",
       "       'premium gasoline', 'movie rental fee', 'pharmacy and toiletries',\n",
       "       'bluetooth speaker', 'soup and salad combo',\n",
       "       'ride to shopping mall', 'gaming stream subscription',\n",
       "       'shoes and handbag', 'gaming controller', 'medium pizza delivery',\n",
       "       'fuel and car wash', 'anime streaming service', 'kitchen utensils',\n",
       "       'camera memory card', 'burger and fries', 'monthly transit card',\n",
       "       'home decor items', 'computer webcam', 'chicken nugget meal',\n",
       "       'gasoline and snacks', 'movie purchase', 'bathroom essentials',\n",
       "       'laptop cooling pad', 'breakfast burrito',\n",
       "       'ride to doctor appointment', 'documentary streaming',\n",
       "       'cosmetics and skincare', 'gaming headset',\n",
       "       'chicken sandwich meal', 'gas and convenience items',\n",
       "       'british tv subscription', 'winter coat purchase',\n",
       "       'computer processor', 'spicy chicken combo',\n",
       "       'ride to train station', 'anime subscription',\n",
       "       'personal care bundle', 'gaming accessories', 'double burger meal',\n",
       "       'premium fuel purchase', 'sports streaming', 'casual clothing',\n",
       "       'graphics card fan', 'tacos and drink', 'ride to concert venue',\n",
       "       'premium cable subscription', 'kitchen appliances',\n",
       "       'computer motherboard', 'western bacon burger',\n",
       "       'gasoline and car care', 'clothing and perfume',\n",
       "       'computer memory upgrade', 'roast beef sandwich meal',\n",
       "       'taxi to airport', 'horror movie streaming', 'home theater setup',\n",
       "       'tablet screen replacement', 'breakfast pancakes',\n",
       "       'fuel and energy drinks', 'art film streaming', 'makeup and tools',\n",
       "       'external hard drive', 'slider combo meal',\n",
       "       'trip to shopping center', 'streaming service', 'home furniture',\n",
       "       'noise canceling headphones', 'coffee and donuts',\n",
       "       'gasoline purchase', 'premium streaming', 'organic groceries',\n",
       "       'streaming device', 'orange chicken bowl', 'daily commuter pass',\n",
       "       'ad supported streaming', 'designer clothing',\n",
       "       'backup storage drive', 'burrito and guac',\n",
       "       'fuel and lottery tickets', 'movie streaming service',\n",
       "       'luxury accessories', 'computer monitor', 'butterburger meal',\n",
       "       'ride to gym', 'educational streaming', 'discounted clothing',\n",
       "       'tablet computer', 'pasta bowl lunch', 'gas and convenience store',\n",
       "       'family streaming', 'cooking equipment', 'wireless earbuds',\n",
       "       'burger and shake', 'ride to meeting', 'outdoor gear',\n",
       "       'sandwich delivery', 'independent film streaming',\n",
       "       'books and magazines', 'gaming keyboard', 'personal pizza',\n",
       "       'ride to restaurant', 'arthouse cinema streaming',\n",
       "       'VR gaming headset', 'chicken finger combo', 'truck stop fuel',\n",
       "       'movie streaming', 'fitness tracker', 'chicken biscuit meal',\n",
       "       'weekly bus pass', 'free streaming upgrade', 'designer handbag',\n",
       "       'smartwatch upgrade', 'grilled chicken bowl', 'fuel and hot food',\n",
       "       'library streaming service', 'furniture and decor',\n",
       "       'studio headphones', 'breakfast taquito', 'ride to hotel',\n",
       "       'premium content', 'athletic wear', 'gaming laptop cooler',\n",
       "       'travel center fuel', 'gaming mouse', 'thick burger meal',\n",
       "       'trip to airport', 'classic movie streaming', 'home accessories',\n",
       "       'computer graphics card', 'truck stop services', 'anime streaming',\n",
       "       'modern furniture', 'fish and chips', 'shared ride service',\n",
       "       'free streaming service', 'kitchen essentials',\n",
       "       'mechanical keyboard', 'discount fuel', 'live streaming service',\n",
       "       'shoe warehouse shopping', 'computer cooling system',\n",
       "       'slider burger meal', 'eco friendly ride', 'cable tv streaming',\n",
       "       'professional clothing', 'wireless charging station'], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoding categorical data\n",
    "\n",
    "print(df.columns)\n",
    "df['category'].unique()\n",
    "# print(df['category'].value_counts())\n",
    "# print(\"cateogory\" ,df['category'].unique())\n",
    "\n",
    "# #giving labels to categories\n",
    "\n",
    "df.head()\n",
    "df['description'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d164ff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date                   ',\n",
      "       ' title                                          ', ' category     ',\n",
      "       ' account     ', ' amount     ', ' currency', ' type    ',\n",
      "       ' transfer-amount', ' transfer-currency', ' to-account  ',\n",
      "       ' receive-amount', ' receive-currency', ' description ', ' due-date',\n",
      "       ' id'],\n",
      "      dtype='object')\n",
      "Index(['description', 'category'], dtype='object')\n",
      "                                        description        category\n",
      "0   Karthik                                           Bills & Fees \n",
      "1   Juice                                             Food & Drinks\n",
      "2   Tire                                              Transport    \n",
      "3   Baba                                              Bills & Fees \n",
      "4   Reward                                            Bills & Fees \n"
     ]
    }
   ],
   "source": [
    "#adding dataset 2 :\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df2=pd.read_csv(\"expenses_income_summary.csv\", on_bad_lines='skip')\n",
    "print(df2.columns)\n",
    "df2.columns = df2.columns.str.strip()\n",
    "df2.drop([\"description\"],inplace=True,axis=1)\n",
    "\n",
    "\n",
    "df2.rename(columns={'title': 'description'}, inplace=True)\n",
    "# print(df2.columns)\n",
    "df2.drop( [\"Date\", \"account\", \"amount\", \"currency\", \"type\", \n",
    "               \"transfer-amount\", \"transfer-currency\", \"to-account\",\n",
    "               \"receive-amount\", \"receive-currency\", \n",
    "               \"due-date\", \"id\"],inplace=True,axis=1)\n",
    "df2.head()\n",
    "print(df2.columns\n",
    ")\n",
    "\n",
    "\n",
    "df2.duplicated().sum()\n",
    "df2.dropna().sum()\n",
    "\n",
    "print(df2.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d384b111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(187, 2)\n",
      "(1087, 2)\n",
      "Index(['description', 'category'], dtype='object')\n",
      "Index(['description', 'category'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['shopping', 'entertainment', 'food', 'transport', 'technology',\n",
       "       ' Bills & Fees ', ' Food & Drinks', ' Transport    ',\n",
       "       '              '], dtype=object)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging\n",
    "\n",
    "print(df.shape)\n",
    "print(df2.shape)\n",
    "print(df.columns)\n",
    "print(df2.columns)\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "df2.columns = df2.columns.str.strip()\n",
    "# df2.replace('        ', pd.NA, inplace=True)\n",
    "\n",
    "df2.dropna(inplace=True)\n",
    "\n",
    "\n",
    "combined_df = pd.concat([df, df2], ignore_index=True)\n",
    "\n",
    "combined_df[\"category\"].unique()\n",
    "\n",
    "# //need to category\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b53dd175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shopping' 'entertainment' 'food' 'transport' 'technology']\n",
      "object\n",
      "\n",
      " ********************************************************    \n",
      "0      wireless headphones purchase\n",
      "1    monthly streaming subscription\n",
      "2         morning coffee and muffin\n",
      "3           ride to downtown office\n",
      "4       smartphone screen protector\n",
      "5                  lunch combo meal\n",
      "6                    daily bus pass\n",
      "7        premium music subscription\n",
      "8       household cleaning supplies\n",
      "9              iPad protective case\n",
      "Name: description, dtype: object\n",
      "\n",
      "\n",
      "Vocabulary (first 20 words):\n",
      "['accessories' 'ad' 'airport' 'and' 'anime' 'app' 'appliances'\n",
      " 'appointment' 'art' 'arthouse']\n",
      "\n",
      "first desciption is  :  wireless headphones purchase\n",
      "\n",
      "Vector for first description:\n",
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "##now preprocess description column\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "X = df['description']       # independent variable\n",
    "y = df['category']          # target variable\n",
    "\n",
    "print(y.unique())\n",
    "print(y.dtype)\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()  #object of CountVectorizer\n",
    "X_vect = vectorizer.fit_transform(X)  #fit and transform the data\n",
    "\n",
    "# Check shape\n",
    "X_vect.shape\n",
    "  # (num_samples, num_features)\n",
    "\n",
    "print()\n",
    "print(\" ********************************************************    \")\n",
    "# Converts text data (description) into numeric vectors so ML models can use it.\n",
    "\n",
    "# How it works:\n",
    "\n",
    "# Builds a vocabulary of all words in your dataset\n",
    "\n",
    "# For each description, counts how many times each word appears\n",
    "\n",
    "# Example:\n",
    "\n",
    "# Vocabulary: ['coffee', 'electricity', 'hut', 'pizza', 'starbucks', 'uber']\n",
    "\n",
    "# Description: \"Starbucks coffee\" â†’ vector [1, 0, 0, 0, 1, 0]\n",
    "\n",
    "\n",
    "#IN ABOVE CASE VOCABULARY \n",
    "\n",
    "#PRINTING DESC OF FIRST 10 ROWS DESCRIPTION\n",
    "print(df['description'][:10])\n",
    "\n",
    "print(end='\\n')\n",
    "\n",
    "# Print the vocabulary\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print() \n",
    "print(\"Vocabulary (first 20 words):\")\n",
    "print(vocab[:10])  # just show first 20 words for readability\n",
    "# Print the vector for the first description\n",
    "vector = X_vect.toarray()[0]\n",
    "print()\n",
    "\n",
    "# ?first descrption ?\n",
    "print(\"first desciption is  : \" ,df['description'][0])\n",
    "print(\"\\nVector for first description:\")\n",
    "print(vector[:10])  # just show first 20 elements for readability\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff76c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b4089d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing of data\n",
    "\n",
    "#data is splitted\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "61eb5204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "#train naive baise model for predicting cateorgy from desc\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3a34d097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer_d.joblib']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#savin my files model\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model,'category_model.joblib')\n",
    "joblib.dump(vectorizer,'vectorizer_d.joblib')\n",
    "\n",
    "# What You've Successfully Created:\n",
    "# 1. category_model.joblib - The Brain ðŸ§ \n",
    "\n",
    "# Contains the trained Naive Bayes model\n",
    "# Knows the patterns: \"coffee\" â†’ food, \"uber\" â†’ transport, etc.\n",
    "# This is what makes the predictions\n",
    "\n",
    "# 2. vectorizer_d - The Translator ðŸ”¤âž¡ï¸ðŸ”¢\n",
    "\n",
    "# Converts text descriptions into numerical arrays\n",
    "# CRITICAL: Must use the same vectorizer for new predictions\n",
    "# Without this, your model won't understand new text\n",
    "\n",
    "\n",
    "# # âŒ WRONG - This won't work!\n",
    "# new_text = \"Starbucks coffee\"\n",
    "# prediction = model.predict(new_text)  # ERROR! Model can't understand text\n",
    "\n",
    "# # âœ… RIGHT - This works!\n",
    "# new_text = \"Starbucks coffee\"\n",
    "# vectorized_text = vectorizer.transform([new_text])  # Convert to numbers\n",
    "# prediction = model.predict(vectorized_text)  # Now model understands!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "09e71785",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "np.str_('transport')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[107]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m category_map = {\u001b[32m0\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mshopping\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mtechnology\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m2\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mfood\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m3\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mentertainment\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m4\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mtransport\u001b[39m\u001b[33m'\u001b[39m}\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m desc, cat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(new_expenses, y_pred_new):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpense: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdesc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m â†’ Predicted Category: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcategory_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: np.str_('transport')"
     ]
    }
   ],
   "source": [
    "# loading model  and testing \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "new_expenses = [\n",
    "    \"Uber ride to office\",\n",
    "    \"Starbucks coffee\",\n",
    "    \" uber new office\",\n",
    "    \"Bought new headphones\"\n",
    "]\n",
    "\n",
    "X_new = vectorizer.transform(new_expenses)\n",
    "\n",
    "\n",
    "model_l =joblib.load('category_model.joblib')\n",
    "\n",
    "y_pred_new = model_l.predict(X_new)\n",
    "# print(\"Accuracy:\", accuracy_score(y_pred, y_pred_new))\n",
    "\n",
    "\n",
    "category_map = {0:'shopping', 1:'technology', 2:'food', 3:'entertainment', 4:'transport'}\n",
    "\n",
    "for desc, cat in zip(new_expenses, y_pred_new):\n",
    "    print(f\"Expense: '{desc}' â†’ Predicted Category: {category_map[cat]}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
