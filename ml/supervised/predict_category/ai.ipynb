{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c9e17dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOADING IMPROVED DATASET ===\n",
      "Dataset shape: (200, 5)\n",
      "\n",
      "First 5 rows:\n",
      "  expense_id  amount   merchant                     description       category\n",
      "0     EXP001   45.50     Amazon    wireless headphones purchase       shopping\n",
      "1     EXP002   12.99    Netflix  monthly streaming subscription  entertainment\n",
      "2     EXP003    8.75  Starbucks       morning coffee and muffin           food\n",
      "3     EXP004   15.20       Uber         ride to downtown office      transport\n",
      "4     EXP005   89.99   Best Buy     smartphone screen protector     technology\n",
      "\n",
      "=== DATA EXPLORATION ===\n",
      "Category distribution:\n",
      "category\n",
      "shopping         40\n",
      "entertainment    40\n",
      "food             40\n",
      "transport        40\n",
      "technology       40\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total categories: 5\n",
      "Categories: ['shopping' 'entertainment' 'food' 'transport' 'technology']\n",
      "\n",
      "=== DATA QUALITY CHECK ===\n",
      "Missing values: 0\n",
      "Duplicate rows: 0\n",
      "\n",
      "Sample descriptions per category:\n",
      "\n",
      "SHOPPING:\n",
      "  - wireless headphones purchase\n",
      "  - household cleaning supplies\n",
      "  - weekly grocery shopping\n",
      "\n",
      "ENTERTAINMENT:\n",
      "  - monthly streaming subscription\n",
      "  - premium music subscription\n",
      "  - monthly video subscription\n",
      "\n",
      "FOOD:\n",
      "  - morning coffee and muffin\n",
      "  - lunch combo meal\n",
      "  - dinner delivery order\n",
      "\n",
      "TRANSPORT:\n",
      "  - ride to downtown office\n",
      "  - daily bus pass\n",
      "  - gasoline fill up\n",
      "\n",
      "TECHNOLOGY:\n",
      "  - smartphone screen protector\n",
      "  - iPad protective case\n",
      "  - office software license\n",
      "\n",
      "=== DATA PREPROCESSING ===\n",
      "Category encoding:\n",
      "  shopping: 0 (40 samples)\n",
      "  technology: 1 (40 samples)\n",
      "  food: 2 (40 samples)\n",
      "  entertainment: 3 (40 samples)\n",
      "  transport: 4 (40 samples)\n",
      "\n",
      "Feature shape: (200,)\n",
      "Target shape: (200,)\n",
      "\n",
      "=== FEATURE EXTRACTION COMPARISON ===\n",
      "Count Vectorizer shape: (200, 240)\n",
      "TF-IDF Vectorizer shape: (200, 240)\n",
      "\n",
      "Top 20 words in vocabulary:\n",
      "['accessories' 'ad' 'airport' 'anime' 'app' 'appliances' 'appointment'\n",
      " 'art' 'arthouse' 'athletic' 'backup' 'bacon' 'bathroom' 'beef' 'biscuit'\n",
      " 'bluetooth' 'books' 'bowl' 'breakfast' 'british']\n",
      "\n",
      "=== MODEL COMPARISON ===\n",
      "Model Performance:\n",
      "------------------------------------------------------------\n",
      "Model                     Accuracy     Percentage  \n",
      "------------------------------------------------------------\n",
      "Naive Bayes (Count)       0.9000       90.00       %\n",
      "Naive Bayes (TF-IDF)      0.8500       85.00       %\n",
      "Logistic Regression       0.9250       92.50       %\n",
      "Random Forest             0.8750       87.50       %\n",
      "SVM                       0.9250       92.50       %\n",
      "------------------------------------------------------------\n",
      "Best Model: Logistic Regression with 92.50% accuracy\n",
      "\n",
      "=== DETAILED ANALYSIS - Logistic Regression ===\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     shopping     0.7273    1.0000    0.8421         8\n",
      "   technology     1.0000    0.8750    0.9333         8\n",
      "         food     1.0000    0.7500    0.8571         8\n",
      "entertainment     1.0000    1.0000    1.0000         8\n",
      "    transport     1.0000    1.0000    1.0000         8\n",
      "\n",
      "     accuracy                         0.9250        40\n",
      "    macro avg     0.9455    0.9250    0.9265        40\n",
      " weighted avg     0.9455    0.9250    0.9265        40\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "               shopping  technology  food  entertainment  transport\n",
      "shopping              8           0     0              0          0\n",
      "technology            1           7     0              0          0\n",
      "food                  2           0     6              0          0\n",
      "entertainment         0           0     0              8          0\n",
      "transport             0           0     0              0          8\n",
      "\n",
      "=== PREDICTION EXAMPLES ===\n",
      "Sample correct and incorrect predictions:\n",
      "\n",
      "✅ CORRECT PREDICTIONS:\n",
      "'tablet computer' → technology ✓\n",
      "'breakfast burrito' → food ✓\n",
      "'clothing and perfume' → shopping ✓\n",
      "'taxi to airport' → transport ✓\n",
      "'fuel and lottery tickets' → transport ✓\n",
      "\n",
      "❌ INCORRECT PREDICTIONS:\n",
      "'tacos and drink' → Actual: food, Predicted: shopping ✗\n",
      "'late night snack order' → Actual: food, Predicted: shopping ✗\n",
      "'bluetooth speaker' → Actual: technology, Predicted: shopping ✗\n",
      "\n",
      "=== SUMMARY ===\n",
      "Dataset size: 200 samples\n",
      "Features: 240 unique words\n",
      "Categories: 5\n",
      "Best model: Logistic Regression\n",
      "Best accuracy: 92.50%\n",
      "Improvement over random guessing: 72.50 percentage points\n",
      "\n",
      "=== TIPS FOR FURTHER IMPROVEMENT ===\n",
      "1. Collect more training data (especially for underrepresented categories)\n",
      "2. Use word embeddings (Word2Vec, GloVe) instead of bag-of-words\n",
      "3. Try ensemble methods combining multiple models\n",
      "4. Add merchant information as an additional feature\n",
      "5. Use more sophisticated text preprocessing (stemming, lemmatization)\n",
      "6. Consider using neural networks for better text understanding\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the improved dataset\n",
    "print(\"=== LOADING IMPROVED DATASET ===\")\n",
    "df = pd.read_csv(\"personal_expense_classification.csv\")  # Use the CSV I created above\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Basic data exploration\n",
    "print(\"\\n=== DATA EXPLORATION ===\")\n",
    "print(\"Category distribution:\")\n",
    "category_counts = df['category'].value_counts()\n",
    "print(category_counts)\n",
    "print(f\"\\nTotal categories: {df['category'].nunique()}\")\n",
    "print(f\"Categories: {df['category'].unique()}\")\n",
    "\n",
    "# Check for data quality\n",
    "print(\"\\n=== DATA QUALITY CHECK ===\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# Check description-category consistency\n",
    "print(\"\\nSample descriptions per category:\")\n",
    "for category in df['category'].unique():\n",
    "    print(f\"\\n{category.upper()}:\")\n",
    "    sample_descriptions = df[df['category'] == category]['description'].head(3).tolist()\n",
    "    for desc in sample_descriptions:\n",
    "        print(f\"  - {desc}\")\n",
    "\n",
    "# Data preprocessing\n",
    "print(\"\\n=== DATA PREPROCESSING ===\")\n",
    "\n",
    "# Remove unnecessary columns\n",
    "df_clean = df.drop(['expense_id', 'amount', 'merchant'], axis=1)\n",
    "\n",
    "# Encode categories\n",
    "category_mapping = {\n",
    "    'shopping': 0, \n",
    "    'technology': 1, \n",
    "    'food': 2, \n",
    "    'entertainment': 3, \n",
    "    'transport': 4\n",
    "}\n",
    "df_clean['category_encoded'] = df_clean['category'].map(category_mapping)\n",
    "\n",
    "print(\"Category encoding:\")\n",
    "for cat, code in category_mapping.items():\n",
    "    count = (df_clean['category_encoded'] == code).sum()\n",
    "    print(f\"  {cat}: {code} ({count} samples)\")\n",
    "\n",
    "# Prepare features and target\n",
    "X = df_clean['description']\n",
    "y = df_clean['category_encoded']\n",
    "\n",
    "print(f\"\\nFeature shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Feature extraction comparison\n",
    "print(\"\\n=== FEATURE EXTRACTION COMPARISON ===\")\n",
    "\n",
    "# Method 1: Count Vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
    "X_count = count_vectorizer.fit_transform(X)\n",
    "\n",
    "# Method 2: TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "print(f\"Count Vectorizer shape: {X_count.shape}\")\n",
    "print(f\"TF-IDF Vectorizer shape: {X_tfidf.shape}\")\n",
    "\n",
    "# Show some vocabulary\n",
    "print(\"\\nTop 20 words in vocabulary:\")\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(feature_names[:20])\n",
    "\n",
    "# Model testing\n",
    "print(\"\\n=== MODEL COMPARISON ===\")\n",
    "\n",
    "# Split data (using stratify to maintain class balance)\n",
    "X_train_count, X_test_count, y_train, y_test = train_test_split(\n",
    "    X_count, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train_tfidf, X_test_tfidf, _, _ = train_test_split(\n",
    "    X_tfidf, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Define models to test\n",
    "models = {\n",
    "    'Naive Bayes (Count)': (MultinomialNB(), X_train_count, X_test_count),\n",
    "    'Naive Bayes (TF-IDF)': (MultinomialNB(), X_train_tfidf, X_test_tfidf),\n",
    "    'Logistic Regression': (LogisticRegression(random_state=42, max_iter=1000), X_train_tfidf, X_test_tfidf),\n",
    "    'Random Forest': (RandomForestClassifier(n_estimators=100, random_state=42), X_train_count, X_test_count),\n",
    "    'SVM': (SVC(random_state=42), X_train_tfidf, X_test_tfidf)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "best_score = 0\n",
    "best_model_name = \"\"\n",
    "best_predictions = None\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Model':<25} {'Accuracy':<12} {'Percentage':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for model_name, (model, X_train, X_test) in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[model_name] = accuracy\n",
    "    \n",
    "    print(f\"{model_name:<25} {accuracy:<12.4f} {accuracy*100:<12.2f}%\")\n",
    "    \n",
    "    # Track best model\n",
    "    if accuracy > best_score:\n",
    "        best_score = accuracy\n",
    "        best_model_name = model_name\n",
    "        best_predictions = y_pred\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"Best Model: {best_model_name} with {best_score*100:.2f}% accuracy\")\n",
    "\n",
    "# Detailed analysis of best model\n",
    "print(f\"\\n=== DETAILED ANALYSIS - {best_model_name} ===\")\n",
    "\n",
    "# Classification report\n",
    "category_names = ['shopping', 'technology', 'food', 'entertainment', 'transport']\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, best_predictions, \n",
    "                          target_names=category_names,\n",
    "                          digits=4))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "cm_df = pd.DataFrame(cm, index=category_names, columns=category_names)\n",
    "print(cm_df)\n",
    "\n",
    "# Show some example predictions\n",
    "print(f\"\\n=== PREDICTION EXAMPLES ===\")\n",
    "print(\"Sample correct and incorrect predictions:\")\n",
    "\n",
    "# Get test indices to match with original descriptions\n",
    "test_indices = y_test.index if hasattr(y_test, 'index') else range(len(y_test))\n",
    "\n",
    "correct_predictions = []\n",
    "incorrect_predictions = []\n",
    "\n",
    "for i, (actual, predicted) in enumerate(zip(y_test, best_predictions)):\n",
    "    if len(correct_predictions) < 5 and actual == predicted:\n",
    "        correct_predictions.append((i, actual, predicted))\n",
    "    elif len(incorrect_predictions) < 5 and actual != predicted:\n",
    "        incorrect_predictions.append((i, actual, predicted))\n",
    "\n",
    "print(\"\\n✅ CORRECT PREDICTIONS:\")\n",
    "for i, actual, predicted in correct_predictions:\n",
    "    # Get the description from test set\n",
    "    test_idx = list(test_indices)[i]\n",
    "    description = X.iloc[test_idx]\n",
    "    print(f\"'{description}' → {category_names[actual]} ✓\")\n",
    "\n",
    "print(\"\\n❌ INCORRECT PREDICTIONS:\")\n",
    "for i, actual, predicted in incorrect_predictions:\n",
    "    test_idx = list(test_indices)[i]\n",
    "    description = X.iloc[test_idx]\n",
    "    print(f\"'{description}' → Actual: {category_names[actual]}, Predicted: {category_names[predicted]} ✗\")\n",
    "\n",
    "# Feature importance (for Random Forest if it's the best)\n",
    "if 'Random Forest' in best_model_name:\n",
    "    print(f\"\\n=== FEATURE IMPORTANCE ===\")\n",
    "    # Get the best model\n",
    "    best_rf_model = models[best_model_name][0]\n",
    "    feature_names = count_vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = best_rf_model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    print(\"Top 15 most important words:\")\n",
    "    for i in range(min(15, len(indices))):\n",
    "        print(f\"{i+1:2d}. {feature_names[indices[i]]:<15} ({importances[indices[i]]:.4f})\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "print(f\"Dataset size: {df.shape[0]} samples\")\n",
    "print(f\"Features: {X_count.shape[1]} unique words\")\n",
    "print(f\"Categories: {len(category_names)}\")\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Best accuracy: {best_score*100:.2f}%\")\n",
    "print(f\"Improvement over random guessing: {(best_score - 0.2)*100:.2f} percentage points\")\n",
    "\n",
    "# Tips for further improvement\n",
    "print(f\"\\n=== TIPS FOR FURTHER IMPROVEMENT ===\")\n",
    "print(\"1. Collect more training data (especially for underrepresented categories)\")\n",
    "print(\"2. Use word embeddings (Word2Vec, GloVe) instead of bag-of-words\")\n",
    "print(\"3. Try ensemble methods combining multiple models\")\n",
    "print(\"4. Add merchant information as an additional feature\")\n",
    "print(\"5. Use more sophisticated text preprocessing (stemming, lemmatization)\")\n",
    "print(\"6. Consider using neural networks for better text understanding\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
